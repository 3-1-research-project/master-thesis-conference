 @article{Bacon_Cheng_Rajan, title={A Uniﬁed Theory of Garbage Collection}, abstractNote={Tracing and reference counting are uniformly viewed as being fundamentally different approaches to garbage collection that possess very distinct performance properties. We have implemented highperformance collectors of both types, and in the process observed that the more we optimized them, the more similarly they behaved — that they seem to share some deep structure.}, author={Bacon, David F and Cheng, Perry and Rajan, V T}, language={en} 
}

@article{mccarthy-tracing-gc,
  title={Recursive functions of symbolic expressions and their computation by machine, part I},
  author={McCarthy, John},
  journal={Communications of the ACM},
  volume={3},
  number={4},
  pages={184--195},
  year={1960},
  publisher={ACM New York, NY, USA}
}

@misc{microsoftFundamentalsGarbage,
	author = {gewarren},
	title = {{F}undamentals of garbage collection - .{N}{E}{T} --- learn.microsoft.com},
	howpublished = {\url{https://learn.microsoft.com/en-us/dotnet/standard/garbage-collection/fundamentals}},
	year = {},
	note = {[Accessed 17-03-2025]},
}

@misc{microsoftWorkstationServer,
	author = {gewarren},
	title = {{W}orkstation vs. server garbage collection ({G}{C}) - .{N}{E}{T} --- learn.microsoft.com},
	howpublished = {\url{https://learn.microsoft.com/en-us/dotnet/standard/garbage-collection/workstation-server-gc}},
	year = {},
	note = {[Accessed 17-03-2025]},
}

@misc{microsoftBackgroundGarbage,
	author = {gewarren},
	title = {{B}ackground garbage collection - .{N}{E}{T} --- learn.microsoft.com},
	howpublished = {\url{https://learn.microsoft.com/en-us/dotnet/standard/garbage-collection/background-gc}},
	year = {},
	note = {[Accessed 17-03-2025]},
}

@misc{golangGuideGarbage,
	author = {},
	title = {{A} {G}uide to the {G}o {G}arbage {C}ollector - {T}he {G}o {P}rogramming {L}anguage --- tip.golang.org},
	howpublished = {\url{https://tip.golang.org/doc/gc-guide}},
	year = {},
	note = {[Accessed 17-03-2025]},
}

@misc{malloc-standard,
	author = {},
	title = {{T}he {O}pen {G}roup {B}ase {S}pecifications {I}ssue 8 --- pubs.opengroup.org},
	howpublished = {\url{https://pubs.opengroup.org/onlinepubs/9799919799/}},
	year = {},
	note = {[Accessed 29-04-2025]},
}

 @inproceedings{Wade_Kulkarni_Jantz_2017, address={Barcelona Spain}, title={AOT vs. JIT: impact of profile data on code quality}, ISBN={978-1-4503-5030-3}, url={https://dl.acm.org/doi/10.1145/3078633.3081037}, DOI={10.1145/3078633.3081037}, abstractNote={Just-in-time (JIT) compilation during program execution and ahead-of-time (AOT) compilation during software installation are alternate techniques used by managed language virtual machines (VM) to generate optimized native code while simultaneously achieving binary code portability and high execution performance. Proﬁle data collected by JIT compilers at run-time can enable proﬁle-guided optimizations (PGO) to customize the generated native code to different program inputs. AOT compilation removes the speed and energy overhead of online proﬁle collection and dynamic compilation, but may not be able to achieve the quality and performance of customized native code. The goal of this work is to investigate and quantify the implications of the AOT compilation model on the quality of the generated native code for current VMs. First, we quantify the quality of native code generated by the two compilation models for a state-of-the-art (HotSpot) Java VM. Second, we determine how the amount of proﬁle data collected affects the quality of generated code. Third, we develop a mechanism to determine the accuracy or similarity for different proﬁle data for a given program run, and investigate how the accuracy of proﬁle data affects its ability to effectively guide PGOs. Finally, we categorize the proﬁle data types in our VM and explore the contribution of each such category to performance.}, booktitle={Proceedings of the 18th ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems}, publisher={ACM}, author={Wade, April W. and Kulkarni, Prasad A. and Jantz, Michael R.}, year={2017}, month=jun, pages={1–10}, language={en} 
}

 @article{Aycock_2003, title={A brief history of just-in-time}, volume={35}, ISSN={0360-0300, 1557-7341}, DOI={10.1145/857076.857077}, abstractNote={Software systems have been using “just-in-time” compilation (JIT) techniques since the 1960s. Broadly, JIT compilation includes any translation performed dynamically, after a program has started execution. We examine the motivation behind JIT compilation and constraints imposed on JIT compilation systems, and present a classification scheme for such systems. This classification emerges as we survey forty years of JIT work, from 1960--2000.}, number={2}, journal={ACM Computing Surveys}, author={Aycock, John}, year={2003}, month=jun, pages={97–113}, language={en} 
}

@misc{shopify-about-page,
	author = {},
	title = {{A}ll {A}bout {S}hopify},
	howpublished = {\url{https://www.shopify.com/about}},
	year = {},
	note = {[Accessed 27-05-2025]},
}

@misc{shopify-yjit,
	author = {},
	title = {{R}uby 3.2’s {Y}{J}{I}{T} is {P}roduction-{R}eady - {S}hopify},
	howpublished = {\url{https://shopify.engineering/ruby-yjit-is-production-ready}},
	year = {},
	note = {[Accessed 27-05-2025]},
}

@misc{matt-haliski-yjit-jemalloc-upgarde,
	author = {},
	title = {{U}pgrading to {R}ails 7.1, {R}uby 3.3, jemalloc and {Y}{J}{I}{T} --- matthaliski.com},
	howpublished = {\url{https://matthaliski.com/blog/upgrading-to-rails-7-1-ruby-3-3-and-jemalloc}},
	year = {},
	note = {[Accessed 27-05-2025]},
}

@misc{facebook-jemalloc,
	author = {},
	title = {{S}calable memory allocation using jemalloc  {E}ngineering at {M}eta --- engineering.fb.com},
	howpublished = {\url{https://engineering.fb.com/2011/01/03/core-infra/scalable-memory-allocation-using-jemalloc/}},
	year = {},
	note = {[Accessed 27-05-2025]},
}

 @article{Berger_Zorn_McKinley, title={Composing High-Performance Memory Allocators}, abstractNote={Current general-purpose memory allocators do not provide sufﬁcient speed or ﬂexibility for modern high-performance applications. Highly-tuned general purpose allocators have per-operation costs around one hundred cycles, while the cost of an operation in a custom memory allocator can be just a handful of cycles. To achieve high performance, programmers often write custom memory allocators from scratch – a difﬁcult and error-prone process.}, author={Berger, Emery D and Zorn, Benjamin G and McKinley, Kathryn S}, language={en} 
}

@standard{c-language-iso9899-2024,
  title        = {{Programming Languages — C}},
  author       = {{International Organization for Standardization}},
  year         = {2024},
  number       = {ISO/IEC 9899:2024},
  institution  = {ISO/IEC},
  note         = {URL: \url{https://www.iso.org/standard/80835.html}},
}

@misc{ronacher-minitwit-commit,
  author       = {Ronacher, Armin},
  title        = {Flask: Minitwit Example (commit 1592c53)},
  year         = {2010},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/pallets/flask/tree/1592c53a664c82d9badac81fa0104af226cce5a7/examples/minitwit}},
  note         = {Commit 1592c53. Accessed: 2025-05-28}
}

@misc{verge-twitter-rebrand-x,
  author       = {Peters, Jay},
  title        = {Twitter’s rebrand to X may actually be happening soon},
  year         = {2023},
  publisher    = {The Verge},
  journal      = {The Verge},
  howpublished = {\url{https://web.archive.org/web/20231013162439/https://www.theverge.com/2023/7/23/23804629/twitters-rebrand-to-x-may-actually-be-happening-soon}},
  note         = {Archived on 2023-10-13. Accessed: 2025-05-28}
}

@book{ling2016university,
  title     = {University Physics Volume 2},
  author    = {Samuel J. Ling and William Moebs and Jeff Sanny},
  year      = {2016},
  publisher = {OpenStax},
  address   = {Houston, TX},
  url       = {https://openstax.org/books/university-physics-volume-2/pages/1-introduction}
}

 @article{Wicht_Vitillo_Chen_Levinthal_2014, title={Hardware Counted Profile-Guided Optimization}, url={http://arxiv.org/abs/1411.6361}, DOI={10.48550/arXiv.1411.6361}, abstractNote={Proﬁle-Guided Optimization (PGO) is an excellent means to improve the performance of a compiled program. Indeed, the execution path data it provides helps the compiler to generate better code and better cacheline packing.}, note={arXiv:1411.6361 [cs]}, number={arXiv:1411.6361}, publisher={arXiv}, author={Wicht, Baptiste and Vitillo, Roberto A. and Chen, Dehao and Levinthal, David}, year={2014}, month=nov, language={en} 
}

@manual{glibc,
  title        = {The GNU C Library},
  author       = {{The GNU Project}},
  organization = {Free Software Foundation},
  year         = {2024},
  note         = {Version 2.39},
  url          = {https://www.gnu.org/software/libc/}
}

@article{benoit2020impact,
  title={Impact of Thermal Throttling on Long-Term Visual Inference in a CPU-Based Edge Device},
  author={Benoit-Cattin, Théo and Velasco-Montero, Delia and Fernández-Berni, Jorge},
  journal={Electronics},
  volume={9},
  number={12},
  pages={2106},
  year={2020},
  publisher={MDPI},
  url={https://www.mdpi.com/2079-9292/9/12/2106}
}
